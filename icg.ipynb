{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_captioning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oye-fdnWq_e"
      },
      "source": [
        "import os  \n",
        "import pandas as pd  \n",
        "import spacy  \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import statistics\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import torchvision.models as models\n",
        "from torch.nn.utils.rnn import pad_sequence  \n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image \n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oybJYpJvrMQg",
        "outputId": "aea5c98a-597c-41dd-a606-86a39fff6d8b"
      },
      "source": [
        "torch.cuda.get_device_name()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfZdHzohXTRE"
      },
      "source": [
        "spacy_en = spacy.load(\"en\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTboL-6QWq79"
      },
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, freq_threshold):\n",
        "        self.itos = {0: \"<pad>\", 1: \"<sos>\", 2: \"<eos>\", 3: \"<unk>\"}\n",
        "        self.stoi = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2, \"<unk>\": 3}\n",
        "        self.freq_threshold = freq_threshold\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "    @staticmethod\n",
        "    def tokenizer_en(text):\n",
        "        return [tok.text.lower() for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "    def build_vocab(self, sentences):\n",
        "        frequencies = {}\n",
        "        i = 4\n",
        "\n",
        "        for sentence in sentences:\n",
        "            for word in self.tokenizer_en(sentence):\n",
        "                if word not in frequencies:\n",
        "                    frequencies[word] = 1\n",
        "\n",
        "                else:\n",
        "                    frequencies[word] += 1\n",
        "\n",
        "                if frequencies[word] == self.freq_threshold:\n",
        "                    self.stoi[word] = i\n",
        "                    self.itos[i] = word\n",
        "                    i += 1\n",
        "\n",
        "    def numericalize(self, text):\n",
        "        tokens = self.tokenizer_en(text)\n",
        "\n",
        "        return [self.stoi[t] if t in self.stoi else self.stoi[\"<unk>\"] for t in tokens]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urxIEQtTWq5R"
      },
      "source": [
        "class LoadDataset(Dataset):\n",
        "    def __init__(self, root_dir, captions_file, transform, freq_threshold=5):\n",
        "        self.root_dir = root_dir\n",
        "        self.df = pd.read_csv(captions_file)\n",
        "        self.transform = transform\n",
        "\n",
        "        self.imgs = self.df[\"image\"]\n",
        "        self.captions = self.df[\"caption\"]\n",
        "\n",
        "        self.vocab = Vocabulary(freq_threshold)\n",
        "        self.vocab.build_vocab(self.captions.tolist())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        caption = self.captions[index]\n",
        "        img_id = self.imgs[index]\n",
        "        img = Image.open(os.path.join(self.root_dir, img_id)).convert(\"RGB\")\n",
        "        img = self.transform(img)\n",
        "\n",
        "        num_caption = [self.vocab.stoi[\"<sos>\"]]\n",
        "        num_caption += self.vocab.numericalize(caption)\n",
        "        num_caption.append(self.vocab.stoi[\"<eos>\"])\n",
        "        num_caption = torch.tensor(num_caption)\n",
        "\n",
        "        return img, num_caption"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYUSZmG6Wq10"
      },
      "source": [
        "class CollateFn:\n",
        "    def __init__(self, pad_idx):\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        imgs = [b[0].unsqueeze(0) for b in batch]\n",
        "        imgs = torch.cat(imgs, dim=0)\n",
        "        captions = [b[1] for b in batch]\n",
        "        captions = pad_sequence(captions, batch_first=False, padding_value=self.pad_idx)\n",
        "\n",
        "        return imgs, captions"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUKisUeAhXNc"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, embed_size, train_CNN=False):\n",
        "        super().__init__()\n",
        "        self.train_CNN = train_CNN\n",
        "        self.inception = models.inception_v3(pretrained=True, aux_logits=False)\n",
        "        self.inception.fc = nn.Linear(self.inception.fc.in_features, embed_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, images):\n",
        "        features = self.inception(images)\n",
        "        return self.dropout(self.relu(features))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYFONHbqhCb6"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, features, captions):\n",
        "        embeddings = self.dropout(self.embedding(captions))\n",
        "        embeddings = torch.cat((features.unsqueeze(0), embeddings), dim=0)\n",
        "        hidden, _ = self.lstm(embeddings)\n",
        "        output = self.linear(hidden)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFyNyf0oiMzr"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers):\n",
        "        super().__init__()\n",
        "        self.cnn = CNN(embed_size)\n",
        "        self.rnn = RNN(embed_size, hidden_size, vocab_size, num_layers)\n",
        "\n",
        "    def forward(self, images, captions):\n",
        "        features = self.cnn(images)\n",
        "        output = self.rnn(features, captions)\n",
        "        return output\n",
        "\n",
        "    def caption_image(self, image, vocab, max_len=50):\n",
        "        caption = []\n",
        "        with torch.no_grad():\n",
        "            x = self.cnn(image).unsqueeze(0)\n",
        "            states = None\n",
        "            \n",
        "            for _ in range(max_len):\n",
        "                hidden, states = self.rnn.lstm(x, states)\n",
        "                output = self.rnn.linear(hidden.squeeze(0))\n",
        "                prediction = output.argmax(1)\n",
        "                caption.append(prediction.item())\n",
        "                x = self.rnn.embedding(prediction).unsqueeze(0)\n",
        "\n",
        "                if vocab.itos[prediction.item()] == \"<eos>\":\n",
        "                    break\n",
        "\n",
        "        return [vocab.itos[i] for i in caption]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI63BPESCOea"
      },
      "source": [
        "transform = transforms.Compose([transforms.Resize((356, 356)), \n",
        "                                transforms.RandomCrop((299, 299)),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSIVm4XIPvEJ"
      },
      "source": [
        "dataset = LoadDataset(\"flickr8k/images/\", \"flickr8k/captions.txt\", transform)\n",
        "pad_idx = dataset.vocab.stoi[\"<pad>\"]\n",
        "batches = DataLoader(dataset=dataset, batch_size=32, num_workers=2, shuffle=True, \n",
        "                    pin_memory=True, collate_fn=CollateFn(pad_idx=pad_idx))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uvrdvbWlchk"
      },
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_CNN = False\n",
        "embed_size = 256\n",
        "hidden_size = 256\n",
        "vocab_size = len(dataset.vocab)\n",
        "num_layers = 1\n",
        "lr = 3e-4\n",
        "epochs = 100"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU67n3tMls-Z",
        "outputId": "7ae5407d-a203-4b82-e0ca-f6c7b6efb712"
      },
      "source": [
        "device"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lsos8156lcfE"
      },
      "source": [
        "net = Net(embed_size, hidden_size, vocab_size, num_layers).to(device)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEtpOr61B-4p",
        "outputId": "2c7a460a-98e7-4bd8-cace-0d38714a9f38"
      },
      "source": [
        "net"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (cnn): CNN(\n",
              "    (inception): Inception3(\n",
              "      (Conv2d_1a_3x3): BasicConv2d(\n",
              "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (Conv2d_2a_3x3): BasicConv2d(\n",
              "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (Conv2d_2b_3x3): BasicConv2d(\n",
              "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (Conv2d_3b_1x1): BasicConv2d(\n",
              "        (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (Conv2d_4a_3x3): BasicConv2d(\n",
              "        (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (Mixed_5b): InceptionA(\n",
              "        (branch1x1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch5x5_1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch5x5_2): BasicConv2d(\n",
              "          (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_1): BasicConv2d(\n",
              "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_2): BasicConv2d(\n",
              "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_3): BasicConv2d(\n",
              "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch_pool): BasicConv2d(\n",
              "          (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (Mixed_5c): InceptionA(\n",
              "        (branch1x1): BasicConv2d(\n",
              "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch5x5_1): BasicConv2d(\n",
              "          (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch5x5_2): BasicConv2d(\n",
              "          (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_1): BasicConv2d(\n",
              "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_2): BasicConv2d(\n",
              "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_3): BasicConv2d(\n",
              "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch_pool): BasicConv2d(\n",
              "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (Mixed_5d): InceptionA(\n",
              "        (branch1x1): BasicConv2d(\n",
              "          (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch5x5_1): BasicConv2d(\n",
              "          (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch5x5_2): BasicConv2d(\n",
              "          (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_1): BasicConv2d(\n",
              "          (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_2): BasicConv2d(\n",
              "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_3): BasicConv2d(\n",
              "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch_pool): BasicConv2d(\n",
              "          (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (Mixed_6a): InceptionB(\n",
              "        (branch3x3): BasicConv2d(\n",
              "          (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_1): BasicConv2d(\n",
              "          (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_2): BasicConv2d(\n",
              "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_3): BasicConv2d(\n",
              "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (Mixed_6b): InceptionC(\n",
              "        (branch1x1): BasicConv2d(\n",
              "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7_1): BasicConv2d(\n",
              "          (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7_2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7_3): BasicConv2d(\n",
              "          (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_1): BasicConv2d(\n",
              "          (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_2): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_3): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_4): BasicConv2d(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_5): BasicConv2d(\n",
              "          (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch_pool): BasicConv2d(\n",
              "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (Mixed_6c): InceptionC(\n",
              "        (branch1x1): BasicConv2d(\n",
              "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7_1): BasicConv2d(\n",
              "          (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7_2): BasicConv2d(\n",
              "          (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7_3): BasicConv2d(\n",
              "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_1): BasicConv2d(\n",
              "          (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_2): BasicConv2d(\n",
              "          (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_3): BasicConv2d(\n",
              "          (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_4): BasicConv2d(\n",
              "          (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_5): BasicConv2d(\n",
              "          (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch_pool): BasicConv2d(\n",
              "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (Mixed_6d): InceptionC(\n",
              "        (branch1x1): BasicConv2d(\n",
              "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7_1): BasicConv2d(\n",
              "          (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7_2): BasicConv2d(\n",
              "          (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7_3): BasicConv2d(\n",
              "          (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_1): BasicConv2d(\n",
              "          (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_2): BasicConv2d(\n",
              "          (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_3): BasicConv2d(\n",
              "          (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_4): BasicConv2d(\n",
              "          (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_5): BasicConv2d(\n",
              "          (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch_pool): BasicConv2d(\n",
              "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (Mixed_6e): InceptionC(\n",
              "        (branch1x1): BasicConv2d(\n",
              "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7_1): BasicConv2d(\n",
              "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7_2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7_3): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_1): BasicConv2d(\n",
              "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_3): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_4): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7dbl_5): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch_pool): BasicConv2d(\n",
              "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (Mixed_7a): InceptionD(\n",
              "        (branch3x3_1): BasicConv2d(\n",
              "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3_2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7x3_1): BasicConv2d(\n",
              "          (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7x3_2): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7x3_3): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch7x7x3_4): BasicConv2d(\n",
              "          (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (Mixed_7b): InceptionE(\n",
              "        (branch1x1): BasicConv2d(\n",
              "          (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3_1): BasicConv2d(\n",
              "          (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3_2a): BasicConv2d(\n",
              "          (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3_2b): BasicConv2d(\n",
              "          (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_1): BasicConv2d(\n",
              "          (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_2): BasicConv2d(\n",
              "          (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_3a): BasicConv2d(\n",
              "          (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_3b): BasicConv2d(\n",
              "          (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch_pool): BasicConv2d(\n",
              "          (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (Mixed_7c): InceptionE(\n",
              "        (branch1x1): BasicConv2d(\n",
              "          (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3_1): BasicConv2d(\n",
              "          (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3_2a): BasicConv2d(\n",
              "          (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3_2b): BasicConv2d(\n",
              "          (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_1): BasicConv2d(\n",
              "          (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_2): BasicConv2d(\n",
              "          (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_3a): BasicConv2d(\n",
              "          (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch3x3dbl_3b): BasicConv2d(\n",
              "          (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (branch_pool): BasicConv2d(\n",
              "          (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "      (dropout): Dropout(p=0.5, inplace=False)\n",
              "      (fc): Linear(in_features=2048, out_features=256, bias=True)\n",
              "    )\n",
              "    (relu): ReLU()\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (rnn): RNN(\n",
              "    (embedding): Embedding(2994, 256)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "    (lstm): LSTM(256, 256)\n",
              "    (linear): Linear(in_features=256, out_features=2994, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct6P3AJDlyfx"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss(ignore_index=dataset.vocab.stoi[\"<pad>\"])\n",
        "opt = optim.Adam(net.parameters(), lr)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rnx5euplydE"
      },
      "source": [
        "for name, param in net.cnn.inception.named_parameters():\n",
        "    if \"fc.weight\" in name or \"fc.bias\" in name:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = train_CNN"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytff0H8YYehW"
      },
      "source": [
        "def save_checkpoint(net, opt, filename):\n",
        "    checkpoint = {\"net_dict\": net.state_dict(), \"opt_dict\": opt.state_dict()}\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "def load_checkpoint(net, opt, filename):\n",
        "    checkpoint = torch.load(filename)\n",
        "    net.load_state_dict(checkpoint[\"net_dict\"])\n",
        "    opt.load_state_dict(checkpoint[\"opt_dict\"])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQMEaKEko4cb"
      },
      "source": [
        "def CaptionImage(net, device, image, dataset):\n",
        "    transform = transforms.Compose([transforms.Resize((299, 299)),\n",
        "                                    transforms.ToTensor(), \n",
        "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    \n",
        "    net.eval()\n",
        "\n",
        "    img = transform(Image.open(image).convert(\"RGB\")).unsqueeze(0)\n",
        "    words = net.caption_image(img.to(device), dataset.vocab)\n",
        "    caption = \"\"\n",
        "    for w in words:\n",
        "        caption += w + \" \"\n",
        "    \n",
        "    net.train()\n",
        "    \n",
        "    print(caption)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P-YnIiip3aI",
        "outputId": "cb2ac2bd-79e2-4b24-e4f6-42066244e619"
      },
      "source": [
        "CaptionImage(net, device, \"test_images/dog.jpg\", dataset)\n",
        "CaptionImage(net, device, \"test_images/child.jpg\", dataset)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bale several busy babies lab playhouse painting combat crouched cliffs bat shop eyed swimsuit festive woodland & bench spraying huddled bows stair raising fan candy strewn outdoor after wand sky flowers wades vehicles headband life kind costumes european turning gravel gated gated gated show lit box handbag retrieving into sister \n",
            "display bib youth drenched food handbag retrieving beret skyscraper stairs safety sky pinata gym cardboard music sailboat tightrope frozen dancers carpeted woods outfit tackled camping double greenery telescope unseen themselves much bulls snowbank watery football except incoming shoulder canoes bathroom kicks snowball fellow stop somthing chip poodle chairs plaid bouquet \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQun1YHynDfq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c27ac7f0-abd5-4809-d234-5fad45ca7105"
      },
      "source": [
        "net.train()\n",
        "for epoch in range(epochs):\n",
        "    batch_losses = []\n",
        "    loop = tqdm(batches, total=len(batches))\n",
        "    for imgs, captions in loop:\n",
        "        imgs = imgs.to(device)\n",
        "        captions = captions.to(device)\n",
        "\n",
        "        outputs = net(imgs, captions[:-1])\n",
        "        loss = loss_fn(outputs.reshape(-1, outputs.shape[2]), captions.reshape(-1))\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward(loss)\n",
        "        opt.step()\n",
        "        batch_losses.append(loss.item())\n",
        "\n",
        "    print(f\" Epoch: {epoch} | Loss: {np.round(sum(batch_losses)/len(batch_losses), 4)}\")\n",
        "    CaptionImage(net, device, \"test_images/dog.jpg\", dataset)\n",
        "    CaptionImage(net, device, \"test_images/child.jpg\", dataset)\n",
        "    print(\"\")\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        save_checkpoint(net, opt, f\"checkpoint_{epoch}.pth.tar\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:24<00:00,  3.29it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 21 | Loss: 2.2553\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is playing with a toy . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:24<00:00,  3.29it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 22 | Loss: 2.2435\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is playing with a toy . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:25<00:00,  3.28it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 23 | Loss: 2.2308\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is running on a grassy field . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:25<00:00,  3.28it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 24 | Loss: 2.2187\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is playing with a toy . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:25<00:00,  3.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 25 | Loss: 2.2067\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is playing with a toy . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:26<00:00,  3.27it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 26 | Loss: 2.1966\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is playing with a toy . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:27<00:00,  3.27it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 27 | Loss: 2.1845\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is playing with a toy . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:28<00:00,  3.26it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 28 | Loss: 2.1756\n",
            "<sos> a dog is running through the water . <eos> \n",
            "<sos> a young boy in a blue shirt is running on a grassy field . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:28<00:00,  3.26it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 29 | Loss: 2.1643\n",
            "<sos> a dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is playing with a toy . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:28<00:00,  3.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 30 | Loss: 2.1575\n",
            "<sos> a dog is running through the water . <eos> \n",
            "<sos> a young boy wearing a blue shirt is running through a field of grass . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:24<00:00,  3.29it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 31 | Loss: 2.1472\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is playing with a toy . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:26<00:00,  3.27it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 32 | Loss: 2.1376\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little boy in a blue shirt is playing with a soccer ball . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:27<00:00,  3.26it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 33 | Loss: 2.1302\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is playing with a toy . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:27<00:00,  3.26it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 34 | Loss: 2.1219\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little boy in a blue shirt is playing with a soccer ball . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:26<00:00,  3.28it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 35 | Loss: 2.1143\n",
            "<sos> a dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is playing with a toy . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:24<00:00,  3.29it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 36 | Loss: 2.1064\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is playing with a toy . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:26<00:00,  3.28it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 37 | Loss: 2.0989\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is running on a grassy lawn . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:26<00:00,  3.28it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 38 | Loss: 2.0923\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is playing with a ball . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:27<00:00,  3.26it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 39 | Loss: 2.0848\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little boy in a red shirt is playing with a ball . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:28<00:00,  3.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 40 | Loss: 2.0781\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is running on a grassy field . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:26<00:00,  3.27it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 41 | Loss: 2.0717\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is running through a grassy field . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1265/1265 [06:28<00:00,  3.26it/s]\n",
            "  0%|          | 0/1265 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Epoch: 42 | Loss: 2.0644\n",
            "<sos> a brown dog is running through the water . <eos> \n",
            "<sos> a little girl in a pink shirt is playing with a ball in a field . <eos> \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 21%|██        | 263/1265 [01:20<04:40,  3.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-c3a558172eb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mbatch_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptions\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcaptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    870\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbMaFUTfPvAl"
      },
      "source": [
        "save_checkpoint(net, opt, f\"checkpoint_{epoch-1}.pth.tar\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdW0ONeVWqmk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc3f2b4f-8c34-4b5b-bc1d-f833153b4f45"
      },
      "source": [
        "CaptionImage(net, device, \"test_images/dog.jpg\", dataset)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<sos> a dog is running through the water . <eos> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys5iWHEtQOS3",
        "outputId": "e9cd9972-d902-4061-ee9e-2bea8df8623e"
      },
      "source": [
        "CaptionImage(net, device, \"test_images/child.jpg\", dataset)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<sos> a little girl in a pink shirt is playing with a ball in a field . <eos> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeJ6ND0WBuNH",
        "outputId": "f9d96a59-6bda-4a6d-ea22-074b0265766d"
      },
      "source": [
        "CaptionImage(net, device, \"test_images/boat.jpg\", dataset)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<sos> a man in a wetsuit is surfing . <eos> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csFvVCJP_pYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8dfbb1-298b-4b22-b19b-48f5e2b92dd3"
      },
      "source": [
        "CaptionImage(net, device, \"test_images/street.jpg\", dataset)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<sos> a man in a red shirt is standing in front of a large crowd of people . <eos> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXQ92_gyFN-k",
        "outputId": "aab3c663-f961-4d7a-9c95-62f6039d11b4"
      },
      "source": [
        "CaptionImage(net, device, \"test_images/elon_musk.jpg\", dataset)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<sos> a man in a white shirt and a woman in a white shirt and black pants . <eos> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anamdy5EFN6k"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkOQ48uZJ0fD"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}